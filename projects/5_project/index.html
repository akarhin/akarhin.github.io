<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Virtual sensor for powertrains | Aku T. Karhinen </title> <meta name="author" content="Aku T. Karhinen"> <meta name="description" content="Summary of a journal publication"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://akarhin.github.io/projects/5_project/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://akarhin.github.io/"> <span class="font-weight-bold">Aku</span> T. Karhinen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Virtual sensor for powertrains</h1> <p class="post-description">Summary of a journal publication</p> </header> <article> <h2 id="introduction">Introduction</h2> <p>In order to conduct proper diagnosis of rotating machines, proper instrumentation is required. For vibration analysis, which is the most used form of condition monitoring for rotating machinery, this can include multiple accelerometers and/or torque transducers. With proper instrumentation, reliable and accurate diagnosis can be conducted. Machine dimensioning, the operating environment or the cost of the sensors can limit the available instrumentation. These factors are twofold when considering critical quantities, where backup sensors are placed in case of a sensor failure.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Virtual_sensor-480.webp 480w,/assets/img/Virtual_sensor-800.webp 800w,/assets/img/Virtual_sensor-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Virtual_sensor.jpg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Virtual sensors, also known as soft sensors, appear as a promising branch of solutions well suited for machine monitoring. Virtual sensors are computational models that estimate physical quantities from other available information about the system, for example secondary measurements or known physical quantities. A virtual sensor can be, for example, used as a backup sensor for sensor prone to breaking due to environmental factors. Virtual sensors have attracted much attention across multiple research fields, including process monitoring and process fault diagnosis. Additionally, virtual sensors have recently gained some attention in mechanical application fields, for example in machine condition monitoring. Virtual sensors are often classified either as model-based virtual sensors, or as data-driven virtual sensors. Model-based virtual sensors apply given system dynamics and domain knowledge, for example in the form of a physics model that simulates the system dynamics, to determine the wanted output quantity. Data-driven virtual sensors on the other hand apply machine learning (ML) techniques to learn patterns directly from historical data without any domain knowledge, but while requiring measured data for training. Commonly used machine learning (ML) models for these sensors include multilayer perceptrons (MLP) and support vector machines (SVM). However, a major drawback of traditional ML-based virtual sensors is the necessity for complex feature extraction and manual feature selection from the training data. Deep learning has been outperforming traditional ML methods in various applications, such as natural language processing and image classification, and has become increasingly popular in mechanical applications like rotating machinery diagnosis. As a result, many current data-driven virtual sensors now rely on more effective deep learning architectures.</p> <p>This project summarizes the implementation done to the publication: Data-driven virtual sensor for powertrains based on transfer learning, available <a href="https://research.aalto.fi/en/publications/data-driven-virtual-sensor-for-powertrains-based-on-transfer-lear" rel="external nofollow noopener" target="_blank">here</a>. The implementation includes the description of the dataset, the model architecture and the results of the implementation.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/VS-480.webp 480w,/assets/img/VS-800.webp 800w,/assets/img/VS-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/VS.jpg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="data">Data</h2> <p>The data used to train the presented virtual sensor was created with a lumped-mass model of a miniatyre sized azimuth thruster. The following image and table describe the utilized model.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/lumped_page-0001-480.webp 480w,/assets/img/lumped_page-0001-800.webp 800w,/assets/img/lumped_page-0001-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/lumped_page-0001.jpg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <table> <thead> <tr> <th><strong>Component</strong></th> <th><strong>Index</strong></th> <th><strong>(I_i) (kgm(^2))</strong></th> <th><strong>(c_i) (Nm/(rad/s))</strong></th> <th><strong>(k_i) (Nm/rad)</strong></th> <th><strong>(d_i) (Nm/(rad/s))</strong></th> </tr> </thead> <tbody> <tr> <td>Driving motor, coupling</td> <td>1</td> <td>(7.94 \times 10^{-4})</td> <td>8.08</td> <td>(1.90 \times 10^{5})</td> <td>0.0030</td> </tr> <tr> <td>Shaft</td> <td>2</td> <td>(3.79 \times 10^{-6})</td> <td>0.29</td> <td>(6.95 \times 10^{3})</td> <td>0</td> </tr> <tr> <td>Elastomer coupling hub</td> <td>3</td> <td>(3.00 \times 10^{-6})</td> <td>0.24</td> <td>90.0</td> <td>0</td> </tr> <tr> <td>Elastomer coupling middle piece</td> <td>4</td> <td>(2.00 \times 10^{-6})</td> <td>0.24</td> <td>90.0</td> <td>0</td> </tr> <tr> <td>Elastomer coupling hubs &amp; shaft</td> <td>5</td> <td>(7.81 \times 10^{-3})</td> <td>0.24</td> <td>90.0</td> <td>0</td> </tr> <tr> <td>Elastomer coupling middle piece</td> <td>6</td> <td>(2.00 \times 10^{-6})</td> <td>0.24</td> <td>90.0</td> <td>0</td> </tr> <tr> <td>Elastomer, coupling hub, encoder &amp; shaft</td> <td>7</td> <td>(3.17 \times 10^{-6})</td> <td>0.00</td> <td>30.13</td> <td>0</td> </tr> <tr> <td>Shaft, encoder &amp; coupling</td> <td>8</td> <td>(5.01 \times 10^{-5})</td> <td>1.78</td> <td>(4.19 \times 10^{4})</td> <td>0</td> </tr> <tr> <td>Torque transducer</td> <td>9</td> <td>(6.50 \times 10^{-6})</td> <td>0.23</td> <td>(5.40 \times 10^{3})</td> <td>0</td> </tr> <tr> <td>Torque transducer &amp; coupling</td> <td>10</td> <td>(5.65 \times 10^{-5})</td> <td>1.78</td> <td>(4.19 \times 10^{4})</td> <td>0</td> </tr> <tr> <td>Shaft</td> <td>11</td> <td>(4.27 \times 10^{-6})</td> <td>0.52</td> <td>(1.22 \times 10^{3})</td> <td>0</td> </tr> <tr> <td>Shaft &amp; gear</td> <td>12</td> <td>(3.25 \times 10^{-4})</td> <td>1.84</td> <td>(4.33 \times 10^{4})</td> <td>0.0031</td> </tr> <tr> <td>Coupling</td> <td>13</td> <td>(1.20 \times 10^{-4})</td> <td>1.32</td> <td>(3.10 \times 10^{4})</td> <td>0</td> </tr> <tr> <td>Shaft</td> <td>14</td> <td>(1.15 \times 10^{-5})</td> <td>0.05</td> <td>(1.14 \times 10^{3})</td> <td>0</td> </tr> <tr> <td>Shaft &amp; coupling</td> <td>15</td> <td>(1.32 \times 10^{-4})</td> <td>1.32</td> <td>(3.10 \times 10^{4})</td> <td>0</td> </tr> <tr> <td>Shaft</td> <td>16</td> <td>(4.27 \times 10^{-6})</td> <td>0.52</td> <td>(1.22 \times 10^{4})</td> <td>0</td> </tr> <tr> <td>Shaft &amp; gear</td> <td>17</td> <td>(2.69 \times 10^{-4})</td> <td>1.88</td> <td>(4.43 \times 10^{4})</td> <td>0.0031</td> </tr> <tr> <td>Coupling</td> <td>18</td> <td>(1.80 \times 10^{-4})</td> <td>5.86</td> <td>(1.38 \times 10^{5})</td> <td>0</td> </tr> <tr> <td>Torque transducer</td> <td>19</td> <td>(2.00 \times 10^{-5})</td> <td>0.85</td> <td>(2.00 \times 10^{4})</td> <td>0</td> </tr> <tr> <td>Torque transducer &amp; coupling</td> <td>20</td> <td>(2.00 \times 10^{-4})</td> <td>5.86</td> <td>(1.38 \times 10^{5})</td> <td>0</td> </tr> <tr> <td>Shaft</td> <td>21</td> <td>(4.27 \times 10^{-6})</td> <td>0.52</td> <td>(1.22 \times 10^{4})</td> <td>0</td> </tr> <tr> <td>Shaft, mass &amp; loading motor</td> <td>22</td> <td>(4.95 \times 10^{-2})</td> <td>-</td> <td>-</td> <td>0.2400</td> </tr> </tbody> </table> <p><em>Table 1: Nominal powertrain parameters used in the simulated powertrain instances. Parameters belonging to the mass moment of inertia ((I_i)), damping ((c_i)) and stiffness ((k_i)) for each powertrain instance were drawn from a uniform distribution between 0.5 and 1.5 times each nominal value separately.</em></p> <h3 id="lumped-mass-modelling">Lumped-mass modelling</h3> <h3 id="the-lstm">The LSTM</h3> <p>The long-short term memory (LSTM) is a recurrent neural network architecture known to work well with temporal patterns present in time-series data, such as vibration measurements. The LSTM operates by a sophisticated gating mechanism modifying information flow to hidden and cell states, essentially functioning as a temporary memory when producing the output to the next layer of the network. This gating mechanism is updated by the following equations: f_t = σ(W_f · [h_(t-1), x_t] + b_f)</p> <p>i_t = σ(W_i · [h_(t-1), x_t] + b_i)</p> <p>o_t = σ(W_o · [h_(t-1), x_t] + b_o)</p> <p>\tilde{c}<em>t = tanh(W_c · [h</em>(t-1), x_t] + b_c)</p> <p>c_t = f_t ⊙ c_(t-1) + i_t ⊙ \tilde{c}_t</p> <p>h_t = o_t ⊙ tanh(c_t)</p> <p>where the variables correspond to the following quantities</p> <ul> <li>( f_t ): Forget gate activation vector</li> <li>( \sigma ): Sigmoid activation function</li> <li>( W_f ): Weight matrix for the forget gate</li> <li>( h_{(t-1)} ): Previous hidden state</li> <li>( x_t ): Current input</li> <li>( b_f ): Bias vector for the forget gate</li> <li>( i_t ): Input gate activation vector</li> <li>( W_i ): Weight matrix for the input gate</li> <li>( b_i ): Bias vector for the input gate</li> <li>( o_t ): Output gate activation vector</li> <li>( W_o ): Weight matrix for the output gate</li> <li>( b_o ): Bias vector for the output gate</li> <li>( \tilde{c}_t ): Candidate cell state</li> <li>( \text{tanh} ): Hyperbolic tangent activation function</li> <li>( W_c ): Weight matrix for the candidate cell state</li> <li>( b_c ): Bias vector for the candidate cell state</li> <li>( c_t ): Cell state</li> <li>( \odot ): Hadamard product (element-wise multiplication)</li> <li>( h_t ): Hidden state</li> </ul> <p>The following image visualizes the flow of this computation throughout a singular time-step.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cell_page-0001-480.webp 480w,/assets/img/cell_page-0001-800.webp 800w,/assets/img/cell_page-0001-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cell_page-0001.jpg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <table> <thead> <tr> <th><strong>Parameter</strong></th> <th><strong>Value</strong></th> </tr> </thead> <tbody> <tr> <td>Window length</td> <td>5000</td> </tr> <tr> <td>Training stride</td> <td>250</td> </tr> <tr> <td>Test stride</td> <td>5000</td> </tr> <tr> <td>Model input dimension</td> <td>5000 × 3</td> </tr> <tr> <td>Model output dimension</td> <td>5000 × 4</td> </tr> <tr> <td>Batch size</td> <td>2</td> </tr> <tr> <td>Cell size</td> <td>81</td> </tr> <tr> <td>Number of layers</td> <td>4</td> </tr> <tr> <td>Dropout</td> <td>0</td> </tr> <tr> <td>Learning rate</td> <td>0.0001</td> </tr> <tr> <td>Epochs</td> <td>15</td> </tr> </tbody> </table> <p><em>Table 2: Model and training parameters used in training and testing. Window length corresponds to the time sample size, stride corresponds to the amount of samples between the start of a data point and the start of the next data point, dimensions correspond to the used array dimensions as input and output of the virtual sensor, batch size to the amount of data points given to the model at a time, layers to the amount of LSTM layers in the model, learning rate to a parameter used in the back propagation algorithm and epochs to the amount of iterations of training through the training set.</em></p> <p>A virtual sensor architecture was employed, consisting of four LSTM layers followed by a fully-connected layer. The suggested virtual sensor takes generated data points as input. Model parameters are listed in Table 2. The training procedure for the data-driven virtual sensor was conducted using traditional supervised learning scenario. During training, rotating speeds and torque near the propeller end of the powertrain were estimated from rotating speeds and torque near the motor end of the powertrain. An error term was established using a loss function. The loss was calculated using mean squared error (MSE):</p> <p>The Mean Squared Error (MSE) is calculated as:</p> <p>[ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 ]</p> <p>where:</p> <ul> <li>( n ) is the number of data points,</li> <li>( y_i ) is the actual value,</li> <li>( \hat{y}_i ) is the predicted value.</li> </ul> <p>The loss terms shown in the Results section have been expressed in MSE. The loss was applied via Stochastic Gradient Descent (SGD) to improve the weights of the model after every training epoch. More precisely, the model was optimized using Adam, a widely used optimizer for neural networks trained with SGD. Adam has been introduced further in <em>Collaborative Lane Detection with Federated Learning</em> and in <a href="https://www.geeksforgeeks.org/adam-optimizer/" rel="external nofollow noopener" target="_blank">here</a>.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Aku T. Karhinen. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>