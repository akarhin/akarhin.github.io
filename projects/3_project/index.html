<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Collaborative Lane Detection with Federated Learning | Aku T. Karhinen </title> <meta name="author" content="Aku T. Karhinen"> <meta name="description" content="A data private approach to lane detection models utilizing federated learning."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://akarhin.github.io/projects/3_project/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://akarhin.github.io/"> <span class="font-weight-bold">Aku</span> T. Karhinen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Collaborative Lane Detection with Federated Learning</h1> <p class="post-description">A data private approach to lane detection models utilizing federated learning.</p> </header> <article> <h2 id="introduction">Introduction</h2> <p>In recent years, advancements in robotics and computer vision have led to significant progress in autonomous driving technologies. Lane detection, as a critical component of such systems, plays a crucial role for intelligent vehicles in perceiving and understanding the surrounding environment. Accurate and robust lane detection is essential for tasks such as vehicle navigation, lane keeping, and advanced driver-assistance systems (ADAS). However, traditional lane detection methods often rely on centralized data collection and processing. That is, that the party training the model needs to have access to the data in order to apply it for learning or testing. This can lead to data privacy concerns that may limit the collaboration of parties in the competing markets or exclude parties overall concerned about data leaks from participating in the development of these types of models.</p> <p>Federated learning (FL) rises as a promising branch of solutions suitable for collaborative machine learning (ML) models. FL algorithms enable collaborative model training across distributed devices, or robots, without the need for data sharing. The fundamental principle behind FL lies in training the models locally while preserving the privacy of the collected data. By training models locally, sensitive data remains on the devices, minimizing the risk of data breaches or privacy violations. Only model updates or gradients are exchanged between the devices or even be seen by the global model, allowing for collaborative training of the global model without exposing the raw data to unwanted eyes.</p> <p>This project focused on applying FL approaches for collaborative lane detection. The primary goal was to portray a promising solution to safeguard data privacy. This study explores and evaluates different FL algorithms suitable for collaborative lane detection on TurtleBots, which are differential drive three wheel robots based on the Robot Operating System (ROS).</p> <p>First, the data acquisition framework is introduced. Second, the FL algorithms and the training scenario is introduced. Third, the results are discussed. Finally, the project concludes by discussing further improvements.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/FL-480.webp 480w,/assets/img/FL-800.webp 800w,/assets/img/FL-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/FL.jpg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="data-gathering-and-processing">Data gathering and processing</h2> <p>The datasets used in this project were collected on a TurtleBot which had a Raspberry Pi camera module 2 attached. The TurtleBot was driven around the three different tracks remotely via an SSH (Secure Shell) connection from a remote Ubuntu laptop. While driving, a rosbag was created on the remote laptop, which recorded all the published messages in the ROS environment. After the recording, the images published by the camera node were exported and fed to an OpenCV algorithm based on Canny edge detection. Each datapoint consisted of the original image resampled to the size (3x96x128) (3 corresponding to the RGB values of each image) as the feature and the same image with same size, but with highlighted lanes as the label.</p> <p>Data was taken during operation of the TurtleBot (while moving) for added realism. Due to time and project constraints, all data was gathered with the same TurtleBot, just in separate tracks, still ensuring that the local models had no access to each other’s data.</p> <h2 id="data-gathering-and-processing-1">Data gathering and processing</h2> <p>The datasets used in this project were collected on a TurtleBot which had a Raspberry Pi camera module 2 attached. The TurtleBot was driven around the three different tracks remotely via an SSH (Secure Shell) connection from a remote Ubuntu laptop. While driving, a rosbag was created on the remote laptop, which recorded all the published messages in the ROS environment. After the recording, the images published by the camera node were exported and fed to an OpenCV algorithm based on Canny edge detection. Each datapoint consisted of the original image resampled to the size (3x96x128) (3 corresponding to the RGB values of each image) as the feature and the same image with same size, but with highlighted lanes as the label. Data was taken during operation of the TurtleBot (while moving) for added realism. Due to time and project constraints, all data was gathered with the same TurtleBot, just in separate tracks, still ensuring that the local models had no access to each other’s data.</p> <h2 id="problem-formulation-and-the-chosen-fl-algorithms">Problem formulation and the chosen FL algorithms</h2> <h3 id="gtvmin">GTVMin</h3> <p>GTVMin, or generalized total variation minimization, is a technique used in various fields such as image processing, machine learning, and signal processing. It aims to find an optimal set of parameters or weights that minimize a given objective function. The research topic of the project can be formulated as a GTVMin problem. By constructing an empirical graph based on the research problem, FL algorithms can be used to solve this special case of GTVMin by applying different iterative optimisation methods. The empirical graph is constructed with a collaborative framework in mind: each edge has the same weight. In some more detailed collaborations, e.g. highly different environment lane detection datasets, the weights could be defined differently. However, the scope of this project is limited to equal weight collaborative lane detection. Each edge corresponds to the information flow, or the flow of weights and gradients, from each local node to the global node. Likewise, the global node shares the current global model along the same edges to the local nodes. Each local node has a dataset containing data from a different environment for the task of lane detection.</p> \[\widehat{\mathbf{w}} \in \underset{\mathbf{w} \in \mathcal{W}}{\arg \min} \sum_{i \in \mathcal{V}} L_{i}(\mathbf{w}^{(i)}) + \lambda \sum_{i, i'} \in \mathcal{E}} A_{i, i'} |\mathbf{w}^{(i)} - \mathbf{w}^{(i')}|_{2}^{2}\] <p>By formulating the research topic as a GTVMin problem, the aim is to produce a general model that can be taught with all local datasets while preserving privacy and improving the overall performance of the lane detection system.</p> <p>Each local dataset was gathered by previously explained methods from different environments and had 150 datapoints per local dataset. The data was split into training sets (100 datapoints for each local dataset distributed into the corresponding local nodes), the validation dataset (the combinations of 25 datapoints from each local dataset = 75 datapoints used for validation scores in the global node) and the testing dataset (the combinations of 25 datapoints from each local dataset = 75 datapoints used for testing). The validation data is shared into the global node only to see how well the models generalise between local dataset, thus not being necessary for actual collaborative lane detection (or open source data could be used instead here). The data split was conducted with random.Random.shuffle(): shuffling a list of datapoints and taking first 100 to the training set, next 25 to the validation set and final 25 into the test set.</p> <p>The feature selection was self-explanatory, an image of a road segment where the lanes need to be highlighted. The dataset was notably downsampled for faster computations and ease of result repeatability. Because the model uses convolutional layers, the more detailed features from the images used are hard to pinpoint. The model used for the global and local models was a Convolutional Neural Network (CNN), which is a traditional neural network architecture used in lane detection algorithms. An identical neural network architecture between local nodes and the global model was used. The models of each node were identical in architecture, since the lane detection models take in and output a same sized image. Since the edge weights were also the same, the only difference between the local nodes were the datasets they could apply during training of the current global model. Each local model and the global model used Mean-Squared Error (MSE) as the loss function:</p> \[\operatorname{MSE} = {\frac {1}{n}}\sum _{i=1}^{n}(Y_{i}-{\hat {Y_{i}}})^{2}\] <p>where:</p> <ul> <li>( n ) is the number of observations.</li> <li>( Y_{i} ) is the actual value.</li> <li>( \hat{Y_{i}} ) is the predicted value.</li> </ul> <p>MSE is a traditional loss function that can be used to compare images when they are in array format. The FedAvg local models were optimised using Adam optimiser, which is an advanced version of traditional SGD optimizer. The FedSGD global model was optimised with traditional SGD: aggregating the gradients and modifying the weights by the product of the gradients and the learning rate.</p> <h2 id="results">Results</h2> <p>After 50 epochs, the average test set MSE for the FedAvg global node was found to be 816.65. It is important to note that this value represents the overall error across the entire empirical graph, since the test set is a combination of data from all local datasets. That is, local nodes did not train own models, but collaborated to train a general global model. For the FedSGD, the MSE was found to be around 1051.63. Similar to the FedAvg results, this value represents the overall error across the empirical graph. Comparing the test set errors of the two methods, we observe the following: FedAvg achieved a lower average test set error, while FedSGD resulted in a slightly higher average. This indicates that FedAvg performed better in terms of generalization and accuracy on the test set. This can as well be observed from the validation scores that have been visualised in Figures. Due to the nature of the problem, the loss and validation errors achieved relatively high values. That is, the method compares each pixel value independently, more likely resulting in more variation between the output and the goal. Nevertheless, the validation losses achieved during the training of FedSGD indicate it not generalising at all, but still being able to find a decently low convergence point. Due to this reason, the FedSGD global model requires more refined techniques for accurate function in all environments. It is important to mention that the test set errors were obtained using global models trained with a fixed number of epochs: the convergence to the validation set was not taken into account during training. The results may vary with different hyperparameters, dataset characteristics, and training settings. The training loss for both FedSGD and FedAvg global models with validation data from each dataset has been visualised in Figures }. It can be observed that the FedSGD converged relatively quickly after few epochs compared to the more slow descent of the FedAvg. The performance of both global models has been visualised for all three datasets in Figure. The FedAvg seems to generalise more, as stated before. However, the FedSGD seems to produce clearer pictures for some datasets while producing uncertain noise for others. Based on these results, the FedAvg FL method was chosen for the presented scenario as the superior FL algorithm with more potential.</p> <h2 id="conclusion">Conclusion</h2> <p>In this study, the problem of data privacy in collaborative lane detection was addressed by investigating the application of FL approaches on TurtleBots. An experimental evaluation of the proposed FL framework was conducted using real-world lane detection datasets captured by TurtleBots. This evaluation provided practical evidence of the feasibility and effectiveness of the FL approach in collaborative lane detection tasks: the global model learned the given training sets with relatively good accuracy. The empirical results highlighted the potential of FL in improving data privacy while maintaining satisfactory detection accuracy. Based on the results, a superior FL method was chosen: FedAvg showcased better generalisation, thus more potential. The introduced FL methods were successful in ensuring data privacy by not requiring nodes to exchange any data directly: only gradients or weights were exchanged during training.</p> <h2 id="further-improvements">Further improvements</h2> <p>Further studies should further emphasise on data privacy preservation through the adoption of encryption, differential privacy and/or secure communication protocols to the suggested framework when exchanging gradients/weights. In addition, the overall performance of the global models should be improved with more advanced architectures and training algorithms. More complex empirical graphs could also be explored when applying FL techniques for lane detection algorithms. For example, when detecting lanes from different environments, different weights could be placed to rarer/common environments when updating the global model.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Aku T. Karhinen. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>